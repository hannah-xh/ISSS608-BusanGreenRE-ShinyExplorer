{
  "hash": "6d220f659e9f31c1ddc1e712651ce079",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"LCA Model Design\"\nauthor: \"Xiaohan Zhang\"\ndate: \"2025-3-26\"\ndate-modified: \"last-modified\"\nexecute:\n  echo: true\n  eval: false\n  warning: false\n  freeze: true\nformat:\n  html:\n    code-fold: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n![](images/clipboard-3863587372.png)\n\n## 1. Introduction\n\nLatent Class Analysis (LCA) offers an effective methodology for\nsegmenting the property market by identifying unobserved subgroups\nwithin the data. This approach enables us to discover distinct property\ntypes based on multiple categorical variables rather than relying solely\non price ranges. The analysis will help understand the different market\nsegments that exist and the key characteristics that define each\nsegment.\n\nThe primary research questions include: 1. What distinct property market\nsegments exist based on property and location characteristics? 2. Which\nvariables are most important in defining these market segments? 3. How\ncan these segments inform property development and marketing strategies?\n\n## 2. R Packages Assessment and Selection\n\n-   `poLCA`: Core package for latent class analysis implementation\n-   `tidyverse`: For data preparation and categorical variable creation\n-   `ggplot2`: For visualization of class probabilities and model\n    comparison\n-   `mclust`: For model evaluation and entropy calculation\n-   Justification for each package selection\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Load packages\nlibrary(readxl)      # For reading Excel files\nlibrary(tidyverse)   # For data manipulation and visualization\nlibrary(poLCA)       # For latent class analysis\nlibrary(mclust)      # For model evaluation\nlibrary(DT)          # For interactive data tables\nlibrary(plotly)      # For interactive plots\n```\n:::\n\n\n\n\n## 3. Data Preparation and Testing\n\n### Dataset Overview\n\nThe analysis is based on a comprehensive property price dataset\ncontaining 52,644 observations across 28 variables. The dataset includes\ncrucial property characteristics and location-based features. Key\nvariables in the dataset include property prices (the target variable),\nphysical property attributes (size, floor level, highest floor in\nbuilding, number of units), location-specific features (distances to\ngreen spaces, water, subway stations, CBD), environmental quality\nindicators (Green Index), and demographic information (population\ndensity, education levels, age distributions). The data spans properties\nwith sizes ranging from 12.49 to 269.68 square meters, located on floors\nranging from -1 to 77, with varying accessibility to amenities.\n\nA thorough examination of the dataset structure revealed complete data\nwith no missing values across all variables. This completeness provided\nan excellent foundation for reliable latent class analysis without the\nneed for imputation or handling of missing data. The data also displays\nconsiderable variation across all key variables, suggesting the\npotential for meaningful market segmentation.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Load data\nProperty_data <- read_excel(\"data/Property_Price_and_Green_Index.xlsx\")\n\n# Examine data structure\nglimpse(Property_data)\n```\n:::\n\n\n\n\n### Variable Discretization Process\n\nFor effective latent class analysis, continuous variables were\ntransformed into categorical format. This discretization process is\nessential as LCA requires categorical indicators. A quantile-based\napproach was primarily employed to ensure balanced distribution of\nobservations across categories while preserving meaningful\ndifferentiation between property types.\n\nFor most variables, tertile cutpoints (33rd and 66th percentiles) were\nused to create three distinct categories representing low (1), medium\n(2), and high (3) values. This approach was applied to Size, Green\nIndex, Subway Distance, Population Density, and Median Age variables.\nThe rationale for using tertiles rather than quartiles or quintiles was\nto maintain sufficient observation counts in each category while still\ncapturing meaningful differentiation.\n\nFor Floor categorization, however, a different approach was taken.\nInstead of percentile-based cutpoints, more intuitive fixed cutpoints\nwere employed: low floors (≤5), medium floors (≤10), and high floors\n(\\>10). This choice reflects typical building classifications and aligns\nwith common property market segmentation practices where floor level\nrepresents a distinct feature of vertical positioning, often associated\nwith views, noise levels, and accessibility considerations.\n\n### Frequency Distribution Verification\n\nFollowing the discretization process, thorough verification of frequency\ndistributions was conducted to ensure the effectiveness of the\ncategorization. The frequency tables for each categorical variable\nconfirmed generally balanced categories with sufficient observations in\neach group to support stable LCA estimation.\n\nSize categories showed excellent balance with approximately 33% of\nobservations in each category (17,374 in category 1, 17,609 in category\n2, and 17,661 in category 3). Similar balanced distributions were\nobserved for Green Index categories, Subway Distance categories, and\nPopulation Density categories, all showing approximately equal\ndistribution across the three levels.\n\nFloor categories showed a somewhat different distribution pattern, with\na higher concentration of properties in category 3 (floors above 10)\ncomprising 26,406 observations, while categories 1 and 2 contained\n13,004 and 13,234 observations respectively. This distribution reflects\nthe actual property landscape in the dataset, with a predominance of\nproperties located on higher floors.\n\nMedian Age categories also showed a relatively balanced distribution\n(17,670 in category 1, 18,504 in category 2, and 16,470 in category 3),\nwith a slightly higher number of properties in areas with middle-aged\npopulations.\n\nThese distribution verifications confirmed that the discretization\nprocess produced meaningful categories with sufficient observations for\nrobust LCA modeling, enabling the identification of distinct property\nmarket segments.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# 1. Initial data checking\nstr(Property_data)\nsummary(Property_data)\n\n# 2. Check for missing values\nmissing_values <- colSums(is.na(Property_data))\nprint(missing_values)\n\n# 3. Variable discretization\nProperty_data_lca <- Property_data %>%\n  mutate(\n    # Size categorization (based on quantiles)\n    Size_cat = case_when(\n      Size <= quantile(Size, 0.33) ~ 1,\n      Size <= quantile(Size, 0.66) ~ 2,\n      TRUE ~ 3\n    ),\n    \n    # Floor categorization\n    Floor_cat = case_when(\n      Floor <= 5 ~ 1,\n      Floor <= 10 ~ 2,\n      TRUE ~ 3\n    ),\n    \n    # Green Index categorization\n    Green_Index_cat = case_when(\n      `Green Index` <= quantile(`Green Index`, 0.33) ~ 1,\n      `Green Index` <= quantile(`Green Index`, 0.66) ~ 2,\n      TRUE ~ 3\n    ),\n    \n    # Distance to subway categorization\n    Subway_Dist_cat = case_when(\n      `Dist. Subway` <= quantile(`Dist. Subway`, 0.33) ~ 1,\n      `Dist. Subway` <= quantile(`Dist. Subway`, 0.66) ~ 2,\n      TRUE ~ 3\n    ),\n    \n    # Population density categorization\n    Pop_Density_cat = case_when(\n      `Pop. Density` <= quantile(`Pop. Density`, 0.33) ~ 1,\n      `Pop. Density` <= quantile(`Pop. Density`, 0.66) ~ 2,\n      TRUE ~ 3\n    ),\n    \n    # Median Age categorization\n    Median_Age_cat = case_when(\n      `Median Age` <= quantile(`Median Age`, 0.33) ~ 1,\n      `Median Age` <= quantile(`Median Age`, 0.66) ~ 2,\n      TRUE ~ 3\n    )\n  )\n\n# Check frequency distribution of categorical variables\nlca_vars <- c(\"Size_cat\", \"Floor_cat\", \"Green_Index_cat\", \"Subway_Dist_cat\", \n              \"Pop_Density_cat\", \"Median_Age_cat\")\n\nfor(var in lca_vars) {\n  cat(\"\\nFrequency table for\", var, \":\\n\")\n  print(table(Property_data_lca[[var]]))\n}\n```\n:::\n\n\n\n\n## 4. LCA Model Fitting and Evaluation\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Create formula\nf <- cbind(Size_cat, Floor_cat, Green_Index_cat, Subway_Dist_cat, \n           Pop_Density_cat, Median_Age_cat) ~ 1\n\n# Set range of classes from 3 to 8\nmin_classes <- 3\nmax_classes <- 8\n\n# Store model results\nlca_results <- list()\nlca_stats <- data.frame(n_classes = min_classes:max_classes)\n\n# Entropy calculation function\nentropy <- function(posterior) {\n  entropy <- -rowSums(posterior * log(posterior), na.rm = TRUE)\n  max_entropy <- -log(1/ncol(posterior))\n  return(1 - mean(entropy) / max_entropy)\n}\n\nset.seed(123)  # For reproducibility\n\n# Previous BIC value for early stopping\nprev_bic <- Inf\nconsecutive_increases <- 0\nmax_consecutive_increases <- 2  # Stop after 2 consecutive BIC increases\n\nfor (i in min_classes:max_classes) {\n  cat(\"\\nFitting model with\", i, \"classes...\\n\")\n  \n  # Optimize for speed\n  lca_results[[i]] <- poLCA(f, Property_data_lca, nclass = i, \n                           maxiter = 1000, nrep = 10)\n  \n  # Store fit statistics\n  idx <- i - min_classes + 1\n  lca_stats$logLik[idx] <- lca_results[[i]]$llik\n  lca_stats$BIC[idx] <- lca_results[[i]]$bic\n  lca_stats$AIC[idx] <- lca_results[[i]]$aic\n  lca_stats$df[idx] <- lca_results[[i]]$resid.df\n  lca_stats$Entropy[idx] <- entropy(lca_results[[i]]$posterior)\n  \n  # Print summary information\n  cat(\"Log-likelihood:\", lca_results[[i]]$llik, \"\\n\")\n  cat(\"BIC:\", lca_results[[i]]$bic, \"\\n\")\n  cat(\"AIC:\", lca_results[[i]]$aic, \"\\n\")\n  \n  # Early stopping check\n  current_bic <- lca_results[[i]]$bic\n  if (current_bic > prev_bic) {\n    consecutive_increases <- consecutive_increases + 1\n    cat(\"BIC increased. Consecutive increases:\", consecutive_increases, \"\\n\")\n    \n    if (consecutive_increases >= max_consecutive_increases) {\n      cat(\"\\nEarly stopping triggered after\", consecutive_increases, \n          \"consecutive BIC increases. Optimal classes may be\", i - consecutive_increases, \"\\n\")\n      break\n    }\n  } else {\n    consecutive_increases <- 0\n  }\n  \n  prev_bic <- current_bic\n}\n\n# Handle the case where we stopped early\nactual_max <- if(exists(\"i\")) min(i, max_classes) else max_classes\nlca_stats <- lca_stats[1:(actual_max - min_classes + 1), ]\n\n# Select best model based on BIC\nbest_model_idx <- which.min(lca_stats$BIC) + min_classes - 1\ncat(\"\\nBest model based on BIC has\", best_model_idx, \"classes.\\n\")\n\n# Visualize model comparison\nggplot(lca_stats, aes(x = n_classes)) +\n  geom_line(aes(y = BIC, color = \"BIC\")) +\n  geom_point(aes(y = BIC, color = \"BIC\")) +\n  geom_line(aes(y = AIC, color = \"AIC\")) +\n  geom_point(aes(y = AIC, color = \"AIC\")) +\n  labs(title = \"LCA Model Comparison\", \n       x = \"Number of Classes\", \n       y = \"Information Criteria\") +\n  theme_minimal()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# After finding best model, save results\nbest_model <- lca_results[[best_model_idx]]\n\n# 1. Save the entire model object\nsaveRDS(best_model, \"best_lca_model.rds\")\n\n# 2. Save the class assignments for easier access\nclass_assignments <- apply(best_model$posterior, 1, which.max)\nwrite.csv(data.frame(id = 1:length(class_assignments), \n                    class = class_assignments), \n         \"lca_class_assignments.csv\", row.names = FALSE)\n\n# 3. Save the model comparison statistics\nwrite.csv(lca_stats, \"lca_model_stats.csv\", row.names = FALSE)\n```\n:::\n\n\n\n\n### Latent Class Analysis (LCA) Results Summary\n\n#### Model Comparison\n\n| Number of Classes | Log-likelihood | BIC | AIC | G² | X² | Number of Parameters |\n|----|----|----|----|----|----|----|\n| 3 classes | -342045.2 | 684503.5 | 684166.4 | 8510.915 | 8480.657 | 38 |\n| 4 classes | -341613.0 | 683780.4 | 683327.9 | 7646.455 | 7608.341 | 51 |\n| 5 classes | -341273.3 | 683242.4 | 682674.6 | 6967.175 | 6990.710 | 64 |\n| 6 classes | -340902.5 | 682642.2 | 681959.1 | 6225.598 | 6076.490 | 77 |\n| 7 classes | -340525.0 | 682028.5 | 681230.1 | 5470.593 | 5492.197 | 90 |\n| 8 classes | -340291.7 | Not shown | Not shown | Not shown | Not shown | Not shown |\n\nNote: All models display the warning \"MAXIMUM LIKELIHOOD NOT FOUND\".\n\n#### Class Population Distribution\n\n##### 3-Class Model\n\n-   Class 1: 12.24%\n-   Class 2: 10.31%\n-   Class 3: 77.45%\n\n##### 4-Class Model\n\n-   Class 1: 52.34%\n-   Class 2: 28.95%\n-   Class 3: 8.51%\n-   Class 4: 10.20%\n\n##### 5-Class Model\n\n-   Class 1: 9.79%\n-   Class 2: 25.23%\n-   Class 3: 11.51%\n-   Class 4: 7.32%\n-   Class 5: 46.15%\n\n##### 6-Class Model\n\n-   Class 1: 11.63%\n-   Class 2: 34.04%\n-   Class 3: 7.00%\n-   Class 4: 11.14%\n-   Class 5: 21.20%\n-   Class 6: 15.00%\n\n##### 7-Class Model\n\n-   Class 1: 9.62%\n-   Class 2: 40.87%\n-   Class 3: 12.53%\n-   Class 4: 9.13%\n-   Class 5: 7.89%\n-   Class 6: 13.21%\n-   Class 7: 6.77%\n\n#### Key Variables in the Analysis\n\nThe LCA examined the following categorical variables: - Size_cat -\nFloor_cat - Green_Index_cat - Subway_Dist_cat - Pop_Density_cat -\nMedian_Age_cat\n\nEach variable was divided into three categories (Pr(1), Pr(2), Pr(3)),\nand the conditional probabilities for these categories across different\nlatent classes were calculated.\n\n#### Model Selection Insights\n\nThe model fit improves (lower BIC and AIC values) as the number of\nclasses increases. The 7-class model shows the best fit among the fully\nreported models, with: - Log-likelihood: -340525.0 - BIC: 682028.5 -\nAIC: 681230.1\n\nHowever, all models show the warning \"MAXIMUM LIKELIHOOD NOT FOUND,\"\nwhich suggests potential convergence issues in the estimation process.\n\n## 5. Parameters and Outputs Determination\n\n### Variables Selection for Latent Class Analysis\n\n#### Primary Variables\n\nFor the latent class analysis model, six categorical variables were\nselected based on their statistical properties and relevance to property\nmarket segmentation:\n\n1.  **Size_cat**: Property size categories derived from the continuous\n    variable \"Size\" (ranging from 12.49 to 269.68 square meters). The\n    discretization created balanced categories with 17,374, 17,609, and\n    17,661 observations across the three groups, providing sufficient\n    data for robust class identification.\n\n2.  **Floor_cat**: Floor level categories divided into low (≤5), medium\n    (≤10), and high (\\>10) floors, resulting in 13,004, 13,234, and\n    26,406 observations respectively. Though slightly imbalanced toward\n    higher floors, this categorization reflects the actual distribution\n    within the dataset.\n\n3.  **Green_Index_cat**: Environmental quality measure (original range:\n    4.163 to 18.927) categorized into three balanced groups containing\n    17,374, 17,404, and 17,866 observations, ensuring stable parameter\n    estimation.\n\n4.  **Subway_Dist_cat**: Distance to nearest subway station (original\n    range: 3.366 to 9.978) transformed into three approximately equal\n    categories with 17,384, 17,395, and 17,865 observations, providing\n    consistent measurement of accessibility.\n\n5.  **Pop_Density_cat**: Population density (original range: 1 to\n    118,182) discretized into three categories with 17,521, 17,271, and\n    17,852 observations, offering balanced representation of\n    neighborhood density characteristics.\n\n6.  **Median_Age_cat**: Demographic indicator (original range: 32.7 to\n    55.4) categorized into three groups with 17,670, 18,504, and 16,470\n    observations, maintaining sufficient data for reliable parameter\n    estimation.\n\nThese variables were retained in the final model as evidenced by their\ninclusion in the LCA formula:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nf <- cbind(Size_cat, Floor_cat, Green_Index_cat, Subway_Dist_cat, Pop_Density_cat, Median_Age_cat) ~ 1\n```\n:::\n\n\n\n\n### Model Selection Criteria\n\nTo determine the optimal number of latent classes, multiple evaluation\ncriteria were employed:\n\n1.  **Bayesian Information Criterion (BIC)**: This was established as\n    the primary selection criterion due to its balanced approach to\n    model fit and complexity. BIC imposes a stronger penalty for model\n    complexity compared to AIC, helping to avoid overfitting. In the\n    analysis, BIC values were calculated for models with different class\n    numbers, ranging from 684,503.5 for the 3-class model to 682,028.5\n    for the 7-class model, with lower values indicating better model fit\n    adjusted for complexity.\n\n2.  **Akaike Information Criterion (AIC)**: Used as a secondary\n    criterion, AIC applies a less severe penalty for model complexity.\n    AIC values ranged from 684,166.4 for the 3-class model to 681,230.1\n    for the 7-class model. The consistent trend in both BIC and AIC\n    provided confidence in model selection decisions.\n\n3.  **Entropy**: This measure was used to assess classification quality\n    and certainty. Higher entropy values indicate clearer distinction\n    between classes and more certain classification of observations. An\n    entropy calculation function was implemented to evaluate how well\n    the model separates observations into distinct classes.\n\n4.  **Interpretability**: Beyond statistical measures, the substantive\n    interpretability of resulting classes was considered. Classes that\n    represented meaningful and distinct property market segments were\n    valued over purely statistical improvements.\n\n### Class Number Determination Process\n\nA systematic and comprehensive approach was adopted to determine the\noptimal number of latent classes:\n\n1.  Models with 3 to 8 latent classes were tested sequentially. This\n    range was chosen based on prior research suggesting that fewer than\n    3 classes would be insufficient to capture market complexity, while\n    more than 8 would likely result in classes too small for meaningful\n    interpretation.\n\n2.  For each potential class number, 10 random starts were employed to\n    avoid local maxima in the likelihood function. This approach\n    increases confidence that the global maximum likelihood solution was\n    found for each model specification.\n\n3.  An early stopping mechanism was implemented to terminate testing\n    when BIC increased consecutively across two class solutions. This\n    approach follows the principle that when BIC begins to increase\n    consistently, additional classes are likely overfitting the data.\n\n4.  Log-likelihood, BIC, and AIC values were carefully tracked across\n    all model iterations to monitor convergence and model fit\n    improvement.\n\n5.  The pattern of BIC and AIC decreases was analyzed, with attention to\n    the point where diminishing returns in model fit improvement\n    occurred with increasing class numbers.\n\nBased on this process, the optimal model was determined to be the\n6-class solution, which showed substantial improvement in BIC\n(682,642.2) compared to simpler models while maintaining interpretable\nand meaningful class structures. While the 7-class model showed a\nslightly lower BIC (682,028.5), the improvement was marginal and came at\nthe cost of less distinct and less interpretable classes.\n\n### Computational Efficiency Considerations\n\nSeveral strategies were implemented to enhance computational efficiency\nwhile maintaining model quality:\n\n1.  Maximum iterations for each model were set to 1,000, striking a\n    balance between ensuring convergence and limiting excessive\n    computation time. This parameter was determined after observing that\n    most models converged well within this limit.\n\n2.  Ten random starts were used for each class number to balance between\n    finding the global maximum likelihood and computational time. This\n    number proved sufficient to consistently find the same maximum\n    likelihood solution across multiple runs.\n\n3.  The early stopping mechanism based on consecutive BIC increases\n    significantly reduced computation time by avoiding unnecessary\n    exploration of models with poorer fit.\n\n4.  A random seed was set to ensure reproducibility while maintaining\n    computational efficiency, allowing for consistent results across\n    repeated analyses.\n\n5.  For models with larger numbers of classes, careful monitoring of\n    log-likelihood, BIC, and AIC values across iterations verified\n    proper convergence and solution stability.\n\nThese efficiency considerations allowed for thorough exploration of the\nmodel space while ensuring practical computation times, enabling the\nidentification of an optimal latent class solution that effectively\ncaptures distinct property market segments.\n\n## 6. UI Component Selection for Shiny Application\n\n### Model Configuration Components for Clustering\n\nBased on the provided images, the following UI components were selected\nfor the Shiny application's clustering functionality:\n\n-   **Number of Clusters Slider**: A slider input ranging from 3 to a\n    maximum of 8 clusters, with the current selection set to 4 clusters\n    as shown in Image 1. This component allows users to intuitively\n    select the desired granularity of market segmentation.\n\n-   **Data Sample Size Slider**: A slider allowing users to select the\n    percentage of data to use for analysis, ranging from 10% to 100%\n    with a current selection at 50%. This enables users to perform\n    exploratory analysis on smaller subsets before running the full\n    analysis.\n\n-   **Variable Selection Panel**: A panel displaying pre-tested\n    variables (Size_cat, Floor_cat, Green_Index_cat) that provide\n    effective clustering results. The panel includes explanatory text\n    informing users that these variables have been validated through\n    preliminary experiments.\n\n-   **Run Cluster Button**: A prominently displayed green button that\n    initiates the clustering process with the selected parameters.\n\n-   ![](images/160237fb2da2e971ef819cd033f758b.png)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# UI code for model configuration\nui_model_config <- fluidRow(\n  column(width = 4,\n    wellPanel(\n      style = \"background-color: #f5f5f5;\",\n      h3(\"Number of Clusters:\"),\n      sliderInput(\"n_clusters\", \"\", min = 3, max = 8, value = 4, step = 1),\n      \n      h3(\"Data Sample Size:\"),\n      sliderInput(\"sample_size\", \"\", min = 10, max = 100, value = 50, step = 10,\n                 labels = c(\"10%\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"100%\")),\n      \n      p(\"Percentage of data used for analysis\"),\n      \n      h3(\"Select Variables:\"),\n      tags$div(\n        style = \"border-left: 4px solid #2E8B57; padding-left: 10px;\",\n        p(\"The following variables have been pre-tested and shown to provide effective clustering results in preliminary experiments.\")\n      ),\n      \n      h4(\"Variables:\"),\n      div(\n        style = \"margin-bottom: 20px;\",\n        actionButton(\"size_cat\", \"Size_cat\", \n                    style = \"background-color: #90EE90; margin-right: 5px;\"),\n        actionButton(\"floor_cat\", \"Floor_cat\", \n                    style = \"background-color: #90EE90; margin-right: 5px;\"),\n        actionButton(\"green_index_cat\", \"Green_Index_cat\", \n                    style = \"background-color: #90EE90;\"),\n        p(\"Select Variables\")\n      ),\n      \n      actionButton(\"run_cluster\", \"Run Cluster\", \n                  style = \"background-color: #2E8B57; color: white; width: 100%; height: 50px;\")\n    )\n  )\n)\n```\n:::\n\n\n\n\n### Results Visualization Components\n\nThe visualization components are organized into tabbed panels for clear\npresentation:\n\n-   **Cluster Proportion Tab**: Displays a horizontal bar chart showing\n    the percentage of data in each cluster, with clear labels for each\n    cluster's proportion (e.g., \"Cluster 1: 27.8%\"). Below the chart,\n    key model fit statistics are displayed (AIC, BIC, Likelihood Ratio,\n    Silhouette Score) in separate green panels.\n-   ![](images/d6fc28048ebae50315e82164fe27d3f.png)\n\n<!-- -->\n\n-   **Cluster Characteristics Tab**: Shows a grouped bar chart depicting\n    variable means for each cluster, allowing users to visually compare\n    how different clusters score on key variables like Floor_cat,\n    Green_Index_cat, and Size_cat. Each cluster is represented by a\n    different shade of green.\n\n<!-- -->\n\n-   ![](images/a2308bd0bf2fca05864041c023b46f4.png)\n-   **Data Explorer Tab**: Provides a tabular view of the raw data with\n    filtering options, allowing users to filter by cluster, search for\n    specific records, and control the number of rows displayed. The\n    table shows detailed property information including prices,\n    coordinates, size, floor, and other attributes.\n\n<!-- -->\n\n-   ![](images/e84c1fdd979cb5e96ac7dd1693ce6a6.png)\n-   **Parallel Coordinates Tab**: Presents a parallel coordinates plot\n    visualizing the relationships between variables across different\n    clusters. Each line represents a property profile, and colors\n    differentiate between clusters, enabling users to understand typical\n    value combinations across each segment.\n-   ![](images/8286d13fc0dfff1851333025ce2b6ba.png)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# UI code for visualization tabs\nui_visualization <- fluidRow(\n  column(width = 8,\n    tabsetPanel(\n      tabPanel(\"Cluster Proportion\",\n        h1(\"Latent Class Analysis\", align = \"right\"),\n        h3(\"Percentage of Data in Each Cluster\"),\n        plotlyOutput(\"cluster_prop_plot\", height = \"300px\"),\n        br(),\n        fluidRow(\n          column(width = 3,\n            div(style = \"background-color: #F0FFF0; padding: 10px; border-radius: 5px;\",\n              h4(\"AIC\"),\n              p(\"-83,572.49\"),\n              actionButton(\"aic_info\", \"\", icon = icon(\"info\"))\n            )\n          ),\n          column(width = 3,\n            div(style = \"background-color: #F0FFF0; padding: 10px; border-radius: 5px;\",\n              h4(\"BIC\"),\n              p(\"-83,633.83\"),\n              actionButton(\"bic_info\", \"\", icon = icon(\"info\"))\n            )\n          ),\n          column(width = 3,\n            div(style = \"background-color: #F0FFF0; padding: 10px; border-radius: 5px;\",\n              h4(\"Likelihood Ratio\"),\n              p(\"0.579\"),\n              actionButton(\"lr_info\", \"\", icon = icon(\"info\"))\n            )\n          ),\n          column(width = 3,\n            div(style = \"background-color: #F0FFF0; padding: 10px; border-radius: 5px;\",\n              h4(\"Silhouette Score\"),\n              p(\"0.348\"),\n              actionButton(\"silhouette_info\", \"\", icon = icon(\"info\"))\n            )\n          )\n        )\n      ),\n      \n      tabPanel(\"Cluster Characteristics\",\n        h1(\"Latent Class Analysis\", align = \"right\"),\n        h3(\"Variable Means by Cluster\"),\n        plotlyOutput(\"var_means_plot\", height = \"400px\")\n      ),\n      \n      tabPanel(\"Data Explorer\",\n        h1(\"Latent Class Analysis\", align = \"right\"),\n        fluidRow(\n          column(width = 4,\n            selectInput(\"cluster_filter\", \"Filter by Cluster:\", \n                      choices = c(\"All\", \"1\", \"2\", \"3\", \"4\"))\n          ),\n          column(width = 4,\n            textInput(\"search_text\", \"Search:\")\n          ),\n          column(width = 4,\n            numericInput(\"rows_display\", \"Rows to Display:\", value = 10)\n          )\n        ),\n        DTOutput(\"data_table\")\n      ),\n      \n      tabPanel(\"Parallel Coordinates\",\n        h1(\"Latent Class Analysis\", align = \"right\"),\n        h3(\"Parallel Coordinates Plot by Cluster\"),\n        plotlyOutput(\"parallel_coords_plot\", height = \"400px\")\n      )\n    )\n  )\n)\n```\n:::\n\n\n\n\n### User Interaction Design Rationale\n\nThe UI design follows several key principles for effective user\ninteraction:\n\n1.  **Clear Visual Hierarchy**: The left sidebar contains all control\n    elements, while the main panel presents results, creating a natural\n    left-to-right workflow.\n\n2.  **Guided Analysis Path**: The tab sequence (Cluster Proportion →\n    Characteristics → Explorer → Parallel Coordinates) guides users\n    through increasingly detailed views of the clustering results.\n\n3.  **Color Consistency**: A green color scheme is used throughout the\n    application, with darker greens for controls and lighter greens for\n    informational panels, creating visual harmony.\n\n4.  **Immediate Feedback**: Key statistics are prominently displayed\n    beneath visualizations, giving users immediate insight into model\n    quality.\n\n5.  **Progressive Disclosure**: Basic information is shown first, with\n    detailed data exploration tools available in later tabs for users\n    who need deeper analysis.\n\nThis design approach creates an intuitive, user-friendly interface that\nbalances simplicity for novice users with sufficient depth for more\nexperienced analysts.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# Combined UI layout\nui <- fluidPage(\n  titlePanel(\"Latent Class Analysis\"),\n  fluidRow(\n    column(width = 4, ui_model_config),\n    column(width = 8, ui_visualization)\n  )\n)\n\n# Define server logic \nserver <- function(input, output, session) {\n  \n  # Reactive for running the cluster analysis\n  cluster_results <- eventReactive(input$run_cluster, {\n    # Code to perform LCA with selected parameters would go here\n    # Return results object\n  })\n  \n  # Generate cluster proportion plot\n  output$cluster_prop_plot <- renderPlotly({\n    # Code to create cluster proportion visualization\n  })\n  \n  # Generate variable means plot\n  output$var_means_plot <- renderPlotly({\n    # Code to create variable means by cluster plot\n  })\n  \n  # Generate data table with filtering\n  output$data_table <- renderDT({\n    # Code to create filtered data table\n  })\n  \n  # Generate parallel coordinates plot\n  output$parallel_coords_plot <- renderPlotly({\n    # Code to create parallel coordinates plot\n  })\n}\n\n# Run the Shiny app\nshinyApp(ui = ui, server = server)\n```\n:::\n\n\n\n\n## 7. Results and Discussion\n\n### Cluster Comparison Analysis\n\nThe LCA clustering explored models with 3 to 8 clusters, with the\nfollowing key findings:\n\n-   **BIC Comparison**: BIC values decreased from 684,503.5 (3-cluster\n    model) to 682,028.5 (7-cluster model), with the rate of improvement\n    slowing after 6 clusters.\n\n-   **Optimal Cluster Solution**: The 6-cluster solution (BIC:\n    682,642.2) provided the best balance between statistical fit and\n    practical interpretability, with clearly differentiated property\n    segments.\n\n-   **Cluster Proportions**: The 6-cluster solution identified one large\n    segment (34.04% of properties), four medium-sized segments (ranging\n    from 11.14% to 21.20%), and one smaller niche segment (7.00%).\n\n### Cluster Profiles\n\nThe 6-cluster solution revealed distinct property segments:\n\n-   **Cluster 1 (11.63%)**: Large properties on high floors,\n    representing the premium segment of the market with superior space\n    and vertical positioning.\n\n-   **Cluster 2 (34.04%)**: Properties with balanced characteristics\n    across all variables, forming the mainstream market segment that\n    appeals to the broadest range of buyers.\n\n-   **Cluster 3 (7.00%)**: Medium-sized properties with high\n    environmental quality in dense areas, creating a specialized\n    urban-environmental niche.\n\n-   **Cluster 4 (11.14%)**: Medium to large properties with poor subway\n    accessibility, representing areas where space compensates for\n    location disadvantages.\n\n-   **Cluster 5 (21.20%)**: Properties in low-density areas with high\n    environmental quality, forming a substantial \"green suburban\" market\n    segment.\n\n-   **Cluster 6 (15.00%)**: Smaller properties with excellent subway\n    accessibility, representing the urban convenience segment where\n    location advantages offset size limitations.\n\n### Market Segmentation Applications\n\nThe clustering results provide practical insights for property market\nanalysis:\n\n-   The identified clusters offer a data-driven framework for property\n    classification that goes beyond simple price tiers.\n\n-   The results reveal important trade-offs defining different market\n    segments: size vs. location, environmental quality vs. density, and\n    floor level vs. accessibility.\n\n-   The balanced distribution of cluster sizes indicates diverse market\n    niches beyond the mainstream segment, suggesting opportunities for\n    specialized development.\n\n## 8. Conclusion\n\n### Key Findings\n\nThe LCA clustering successfully identified six distinct property market\nsegments, each with unique characteristic combinations:\n\n1.  Premium large, high-floor properties\n2.  Mainstream balanced-attribute properties\n3.  Urban-environmental properties combining density with green\n    amenities\n4.  Spacious but less accessible properties\n5.  Green suburban properties with environmental quality and low density\n6.  Urban convenience properties with excellent accessibility but\n    limited size\n\n### Applications\n\nThe clustering results provide practical applications for property\nmarket analysis:\n\n-   Development planning guidance by identifying underserved market\n    segments\n-   Improved targeting of marketing messages to specific property buyer\n    segments\n-   Better understanding of value drivers across different property\n    types\n\n### Limitations and Future Directions\n\nSome limitations of the current analysis include:\n\n-   The discretization of variables into three categories may have\n    simplified some distinctions\n-   The exclusion of variables like construction year and socioeconomic\n    indicators\n\nFuture work could enhance the analysis by: - Incorporating additional\nrelevant variables - Applying the clustering approach to different\ngeographical areas - Extending the analysis to include price data to\nquantify segment premiums\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}